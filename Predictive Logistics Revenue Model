import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Step 1: Create Dummy Dataset
np.random.seed(42)
data = {
    'total_loads': np.random.randint(50, 500, size=200),
    'freight_delays': np.random.randint(0, 20, size=200),
    'profit_margin': np.random.uniform(0.1, 0.5, size=200),
    'engagement_score': np.random.uniform(1, 10, size=200),
    'region': np.random.choice(['North', 'South', 'East', 'West'], size=200),
    'revenue': np.random.uniform(5000, 20000, size=200)  # Target variable
}

df = pd.DataFrame(data)

# One-hot encoding for categorical variables
df = pd.get_dummies(df, columns=['region'], drop_first=True)

# Step 2: Define Features and Target
X = df.drop(columns=['revenue'])
y = df['revenue']

# Step 3: Split the Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train the Model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Step 5: Predict and Evaluate
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-Squared: {r2}")

# Optional: Feature Importance
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("\nFeature Importance:")
print(feature_importance)
